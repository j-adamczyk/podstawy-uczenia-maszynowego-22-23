{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metody oparte o sąsiedztwo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konfiguracja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laboratorium składa się z 2 części:\n",
    "1. kNN w uczeniu nadzorowanym\n",
    "2. Wyszukiwanie\n",
    "\n",
    "W pierwszej części użyjemy standardowych bibliotek oraz dodatkowo:\n",
    "- `pynndescent` dla approximate nearest neighbors (ANN)\n",
    "- `pyarrow` do odczytu zbioru danych w formacie Parquet\n",
    "\n",
    "W drugiej części natomiast do wektoryzacji obiektów użyjemy stosu do uczenia głębokiego opartego o PyTorcha i torchvision. Dodatkowo użyjemy:\n",
    "- `sentence-transformers` - podobna do popularnej biblioteki Transformers, ale obsługuje głównie modele do uczenia nienadzorowanego, niewymagające fine-tuningu\n",
    "- `tqdm` dla wyświetlania progress bar\n",
    "\n",
    "**Uwaga:** trzeba użyć wersji Numpy'a 1.23.X, bo wersja 1.24 wprowadziła dużo breaking changes i inne biblioteki (np. PyNNDescent) jeszcze nie są zaktualizowane.\n",
    "\n",
    "PyTorcha i torchvision zainstaluj [w wersji odpowiedniej dla twojego systemu i środowiska](https://pytorch.org/get-started/locally/). GPU nie będzie nam potrzebne, ale możesz go użyć, jeżeli jest odpowiednio skonfigurowane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install numpy==1.23.5 pandas matplotlib scikit-learn missingno pyarrow pynndescent sentence-transformers tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zbiór danych - klasyfikacja danych numerycznych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystamy zbiór danych [Codon usage](https://archive.ics.uci.edu/ml/datasets/Codon+usage) z dziedziny bioinformatyki. Został on zaprezentowany w artykule ([link do wersji Open Access](https://www.nature.com/articles/s41598-023-28965-7):\n",
    "\n",
    "Hallee, Logan, and Bohdan B. Khomtchouk. *\"Machine learning classifiers predict key genomic and evolutionary traits across the kingdoms of life.\"* Scientific Reports 13.1 (2023): 2088.\n",
    "\n",
    "Autorzy wykonywali na nim wiele analiz, ale nas interesuje podstawowa - przewidywanie, z jakiego królestwa (kingdom) pochodzi komórka, na podstawie rozkładu kodonów w jej sekwencjonowanym RNA. Analiza DNA oraz RNA jest podstawowym zadaniem bioinformatyki. Kodony (codons) to trójki nukleotydów, np. UGC, i większość zapisuje pewien aminokwas (z wyjątkiem trzech kodonów stopu), który jest wykorzystywany w syntezie białek.\n",
    "\n",
    "Problem jest taki, że w praktyce trzeba sekwencjonować DNA/RNA z wielu komórek, więc trzeba je namnożyć w laboratorium. Niestety nie da się uzyskać idealnej czystości, i zawsze jest szansa, że próbka zostanie zanieczyszczona, np. bakteriami. Wtedy oprócz interesujących nas komórek (np. zwierzęcych) otrzymamy inne, których trzeba się pozbyć przed dalszą analizą. Tutaj właśnie wchodzi ML - dokonamy klasyfikacji, z jakiego królestwa (a właściwie domeny) pochodzi kod RNA, żeby pomóc w takich sytuacjach.\n",
    "\n",
    "Dla uproszczenia, autorzy, zamiast klasyfikować królestwo, klasyfikują [domenę](https://pl.wikipedia.org/wiki/Domena_(biologia)) organizmu. Są to jednostki o poziom wyżej w systematyce taksonomicznej. Do tego dokładamy wirusy i bakteriofagi. Mamy zatem klasy:\n",
    "1. Archaea ([archeony](https://pl.wikipedia.org/wiki/Archeony))\n",
    "2. Bacteria ([bakterie](https://pl.wikipedia.org/wiki/Bakterie))\n",
    "3. Eukariota ([eukarionty](https://pl.wikipedia.org/wiki/Eukarionty)) - między innymi ludzie\n",
    "4. Viruses ([wirusy](https://pl.wikipedia.org/wiki/Wirusy)) - nie są organizmami żywymi, więc nie są częścią typowej taksonomii, ale są ważne w badaniach mikrobiologicznych\n",
    "5. Bacteriophages ([bakteriofagi](https://pl.wikipedia.org/wiki/Bakteriofag)) - rodzaj wirusów atakujących tylko bakterie, używane m.in. [w badaniach nad mikrobiomem jelitowym](https://kids.frontiersin.org/articles/10.3389/frym.2019.00146)\n",
    "\n",
    "Szczegółowy opis zbioru znajduje się [na stronie UCI](https://archive.ics.uci.edu/ml/datasets/Codon+usage). W skrócie:\n",
    "1. `Kingdom` - królestwo, z którego pochodzi komórka. Podział jest tutaj dość szczegółowy, ale organizmy te można pogrupować w praktyce na bakterie (bacteria), wirusy (viruses) i eukarionty (eukariota).\n",
    "2. `DNAtype` - używana w innych analizach w artykule.\n",
    "3. `SpeciesID` - numer gatunku.\n",
    "4. `Ncodons` - liczba kodonów zmierzona dla danej komórki.\n",
    "5. `SpeciesName` - nazwa gatunku.\n",
    "\n",
    "Dalsze kolumny to znormalizowany ułamek kodonów poszczególnych typów w RNA danej komórki. W związku z tym, że dane są już znormalizowane, nie ma potrzeby ich skalowania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"codon_usage.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mamy warning co do typu - niedobrze. Sprawdźmy typy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolumny `UUU` i `UUC` powinny być floatami - niedobrze. Na szczęście to tylko literówka w jednym wierszu, co można sprawdzić w danych. Usuniemy ją po prostu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pd.to_numeric(df[\"UUU\"], errors=\"coerce\").notnull()].copy()\n",
    "\n",
    "df = df.copy()  # to avoid irritating SettingWithCopyWarning\n",
    "\n",
    "df[\"UUU\"] = df.loc[:, \"UUU\"].astype(float)\n",
    "df[\"UUC\"] = df.loc[:, \"UUC\"].astype(float)\n",
    "\n",
    "df.dtypes.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 1 (1.5 punktu)**\n",
    "\n",
    "*Preprocessing danych (wzorowany na artykule)*\n",
    "\n",
    "1. Usuń wiersze mające mniej niż 1000 kodonów\n",
    "2. Usuń wiersze dla plazmidów (wartość `plm` dla królestwa)\n",
    "3. Usuń kolumny bezużyteczne dla ML: `DNAtype`, `SpeciesID`, `Ncodons`, `SpeciesName`\n",
    "4. Zakoduj klasy (kolumna `Kingdom`):\n",
    "  - 0 - archaea, `arc`\n",
    "  - 1 - bacteria, `bct`\n",
    "  - 2 - eukaryota, `pln`, `inv`, `vrt`, `mam`, `rod`, `pri`\n",
    "  - 3 - bacteriophages (phages), `phg`\n",
    "  - 4 - viruses (viral cells), `vrl`\n",
    "5. Wyodrębnij klasy jako osobną zmienną `y`. Pamiętaj o usunięciu tej kolumny z oryginalnego DataFrame'a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzimy jeszcze rozkład klas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_frequencies = y.value_counts() / y.sum()\n",
    "class_frequencies = class_frequencies.sort_index()\n",
    "class_frequencies.index = [\"Archaea\", \"Bacteria\", \"Eukaryota\", \"Phages\", \"Viruses\"]\n",
    "\n",
    "ax = class_frequencies.plot.bar(rot=0)\n",
    "plt.title(\"Class frequencies in %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać, mamy nie tylko klasyfikację wieloklasową, ale na dodatek klasyfikację niezbalansowaną. W takim przypadku trzeba użyć odpowiednich metryk. Wzorując się na artykule, użyjemy **macro-averaged F1-score**. Jest to proste rozwinięcie F1-score na wiele klas.\n",
    "\n",
    "Dla przypomnienia, w klasyfikacji binarnej, F1-score to średnia harmoniczna precyzji (precision) i czułości (recall):\n",
    "\n",
    "$$\n",
    "F1 = \\frac{2}{recall^{-1} + precision^{-1}} = 2 * \\frac{precision * recall}{precision + recall} = \\frac{2 * TP}{2 * TP + FP + FN}\n",
    "$$\n",
    "\n",
    "Macro-averaging oznacza, że najpierw obliczamy F1-score dla każdej klasy, a później bierzemy ich średnią. Żeby taka średnia była wysoka, to musimy mieć wysoki wynik na wszystkich 5 klasach, w tym 2 mniejszościowych, więc uwzględnimy niezbalansowanie klas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasyfikator kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wytrenujemy teraz podstawowy algorytm k najbliższych sąsiadów, korzystając z samych wartości domyślnych ze Scikit-learn: 5 sąsiadów, metryka euklidesowa, brak ważenia.\n",
    "\n",
    "Zgodnie z artykułem, wykorzystamy zwykłą metodę holdout do testowania, dzieląc zbiór na treningowy i testowy w proporcjach 80%-20%. Zrobimy to ze **stratyfikacją (stratification)**, czyli tak, żeby rozkład klas był taki sam w obu podzbiorach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df, y, test_size=0.2, random_state=0, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "clf = KNeighborsClassifier(n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_score_train = clf.predict(X_train)\n",
    "y_pred_score_test = clf.predict(X_test)\n",
    "\n",
    "f1_train = f1_score(y_train, y_pred_score_train, average=\"macro\")\n",
    "f1_test = f1_score(y_test, y_pred_score_test, average=\"macro\")\n",
    "\n",
    "print(f\"F1 train: {100 * f1_train:.2f}%\")\n",
    "print(f\"F1 test: {100 * f1_test:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki są całkiem niezłe, ale jest jeszcze miejsce na poprawę. Być może zmiana liczby sąsiadów albo metryki, albo też dodanie ważenia sąsiadów da nam jeszcze kilka procent.\n",
    "\n",
    "W przypadku wielu klas samo agregowane F1 nie zawsze mówi jednak wszystko. Zawsze warto sprawdzić **macierz pomyłek (confusion matrix)**. Co ważne, można ją rysować albo z surową liczbą przykładów, albo znormalizować, żeby dostać wyniki w ułamku (zakres wartości 0-1). Pierwsza możliwość jest przydatna, kiedy mamy niezbalansowane klasy i patrzymy na ogólną jakość klasyfikatora. Znormalizowane wykresy są z kolei przydatne, kiedy przyglądamy się klasom z osobna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    clf, X_test, y_test\n",
    ")\n",
    "plt.title(\"Confusion matrix (no normalization)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    clf, X_test, y_test, normalize=\"true\"\n",
    ")\n",
    "plt.title(\"Confusion matrix (row-normalized)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki są całkiem niezłe, w końcu mamy wysokie F1. Widać jednak, że dość często mylimy klasę 0 (archeony) oraz klasę 3 (bakteriofagi) z klasą 1 (bakterie) - jest to problematyczne, ale zrozumiałe, bo tych klas jest najmniej.\n",
    "\n",
    "Po tuningu powinniśmy otrzymać lepsze wyniki. Na dobry początek sprawdzimy różną liczbę sąsiadów. Trzeba zwrócić uwagę, że jeżeli nasza metryka ma jakieś argumenty, to trzeba użyć funkcji `make_scorer` i przekazać wynik do `GridSearchCV`.\n",
    "\n",
    "Zwróć też uwagę, że skoro przekazujemy `n_jobs=-1` do klasyfikatora, to grid search dostaje `n_jobs=None`, żeby mieć tyle procesów, co rdzeni procesora. Przy okazji zmierzymy też czas tuningu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "clf = KNeighborsClassifier(n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_neighbors\": list(range(1, 51)),\n",
    "}\n",
    "\n",
    "multiclass_f1 = make_scorer(\n",
    "    f1_score,\n",
    "    average=\"macro\", \n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "cv = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=multiclass_f1,\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "time_start = time()\n",
    "cv.fit(X_train, y_train)\n",
    "time_end = time()\n",
    "\n",
    "print(f\"Optimal number of neighbors: {cv.best_params_['n_neighbors']}\")\n",
    "print(f\"Tuning time: {time_end - time_start:.2f} s\")\n",
    "\n",
    "y_pred_score_train = cv.predict(X_train)\n",
    "y_pred_score_test = cv.predict(X_test)\n",
    "\n",
    "f1_train = f1_score(y_train, y_pred_score_train, average=\"macro\")\n",
    "f1_test = f1_score(y_test, y_pred_score_test, average=\"macro\")\n",
    "\n",
    "print(f\"F1 train: {100 * f1_train:.2f}%\")\n",
    "print(f\"F1 test: {100 * f1_test:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co ciekawe, po tuningu nie tylko nie mamy lepszego wyniku, ale wręcz przeuczamy bardziej! Tak się niestety zdarza - tuning opiera się na wyniku na zbiorze walidacyjnym, które nie zawsze są dobrą estymatą. Pewnym sposobem na ominięcie tego jest zmniejszenie zakresu dla hiperparametru. Tutaj wiemy, że:\n",
    "- im mniejsza liczba sąsiadów, tym większa wariancja (mocniejszy overfitting) i na odwrót\n",
    "- domyślna liczba sąsiadów to 5\n",
    "- przy 4 przeuczamy mocniej\n",
    "\n",
    "Można więc po prostu sprawdzać zakres od 5 wzwyż. Do tego czeka nas jeszcze tuning metryki i ważenia sąsiadów.\n",
    "\n",
    "**Zadanie 2 (1.5 punktu)**\n",
    "\n",
    "*Tuning kNN*\n",
    "\n",
    "1. Dokonaj tuningu: liczby sąsiadów (zakres [5, 25]), metryki (euklidesowa, Manhattan, cosinusowa) oraz ważenia sąsiadów (brak vs ważenie odległością). Jakie są optymalne wartości hiperparametrów?\n",
    "2. Zmierz czas. Czy twoim zdaniem to długo, dla zbioru, który ma ok. 10k próbek uczących?\n",
    "3. Czy macierz pomyłek dla zbioru testowego wygląda sensownie, szczególnie dla klas mniejszościowych? Czy udało się uzyskać wynik lepszy od bazowego?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// skomentuj tutaj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate Nearest Neighbors (ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postaramy się teraz przyspieszyć nasz klasyfikator, w zamian za odrobinę dokładności, za pomocą algorytmu przybliżonych najbliższych sąsiadów, a konkretnie NNDescent.\n",
    "\n",
    "Twórcy Scikit-learn'a zdawali sobie sprawę, że algorytmy znajdowania najbliższych sąsiadów to aktywne pole rozwoju, dlatego stworzyli klasę (i interfejs) `KNeighborsTransformer`, pozwalającą integrować zewnętrzne rozwiązania. Działa ona zarówno do klasyfikacji / regresji kNN, jak i do innych algorytmów opartych o sąsiedztwo, które budują graf najbliższych sąsiadów. W przypadku jego użycia trzeba podać `metric=\"precomputed\"`, bo obliczaniem odległości zajmuje się osobny algorytm.\n",
    "\n",
    "Implementacja PyNNDescent korzysta właśnie z tego rozwiązania, co gwarantuje łatwość użycia - klasa `PyNNDescentTransformer` dziedziczy po `KNeighborsTransformer`. Zobaczmy, jak to działa. Wykorzystamy funkcję `make_pipeline()`, która buduje obiekt `Pipeline`, ale nie wymaga podawania nazw kolejnych elementów.\n",
    "\n",
    "**Uwaga:** PyNNDescent dla wydajności korzysta z Numby, czyli kompilatora JIT (Just-In-Time). Dzięki temu działa to bardzo szybko, ale pierwszy import i wykonanie zajmuje sporo czasu. Wykonaj kod 2 razy - za drugim razem będzie o wiele szybciej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "\n",
    "def benchmark_knn_and_ann(\n",
    "    sklearn_knn, \n",
    "    pynndescent_ann, \n",
    "    X_train, \n",
    "    X_test, \n",
    "    y_train, \n",
    "    y_test,\n",
    ") -> None:\n",
    "    # training\n",
    "    start_time = time()\n",
    "    sklearn_knn.fit(X_train, y_train)\n",
    "    end_time = time()\n",
    "\n",
    "    sklearn_knn_fit_time = end_time - start_time\n",
    "\n",
    "    start_time = time()\n",
    "    pynndescent_ann.fit(X_train, y_train)\n",
    "    end_time = time()\n",
    "\n",
    "    pynndescent_ann_fit_time = end_time - start_time\n",
    "\n",
    "    # prediction\n",
    "\n",
    "    start_time = time()\n",
    "    y_pred_sklearn = sklearn_knn.predict(X_test)\n",
    "    end_time = time()\n",
    "\n",
    "    sklearn_knn_predict_time = end_time - start_time\n",
    "\n",
    "    start_time = time()\n",
    "    y_pred_pynndescent = pynndescent_ann.predict(X_test)\n",
    "    end_time = time()\n",
    "\n",
    "    pynndescent_ann_predict_time = end_time - start_time\n",
    "    \n",
    "    f1_knn = f1_score(y_test, y_pred_sklearn, average=\"macro\")\n",
    "    f1_ann = f1_score(y_test, y_pred_pynndescent, average=\"macro\")\n",
    "\n",
    "    print(f\"Scikit-learn training time: {sklearn_knn_fit_time:.2f}\")\n",
    "    print(f\"PyNNDescent training time: {pynndescent_ann_fit_time:.2f}\")\n",
    "    print()\n",
    "    print(f\"Scikit-learn prediction time: {sklearn_knn_predict_time:.2f}\")\n",
    "    print(f\"PyNNDescent prediction time: {pynndescent_ann_predict_time:.2f}\")\n",
    "    print()\n",
    "    print(f\"Scikit-learn F1: {100 * f1_knn:.2f}%\")\n",
    "    print(f\"PyNNDescent F1: {100 * f1_ann:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynndescent import PyNNDescentTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "sklearn_knn = KNeighborsClassifier(metric=\"euclidean\")\n",
    "\n",
    "pynndescent_ann = make_pipeline(\n",
    "    PyNNDescentTransformer(metric=\"euclidean\", random_state=0),\n",
    "    KNeighborsClassifier(metric=\"precomputed\"),\n",
    ")\n",
    "\n",
    "benchmark_knn_and_ann(sklearn_knn, pynndescent_ann, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czas treningu jest dłuższy - to oczekiwany wynik. Natomiast czas predykcji jest podobny - wynika to z tego, że dla metryki euklidesowej k-d tree jest bardzo wydajne. Wynik jest bardzo podobny, więc mamy dobre przybliżenie.\n",
    "\n",
    "Sprawdźmy metrykę Manhattan, dla której typowo k-d tree radzi sobie nieco gorzej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sklearn_knn = KNeighborsClassifier(metric=\"manhattan\")\n",
    "\n",
    "pynndescent_ann = make_pipeline(\n",
    "    PyNNDescentTransformer(metric=\"manhattan\", random_state=0),\n",
    "    KNeighborsClassifier(metric=\"precomputed\"),\n",
    ")\n",
    "\n",
    "benchmark_knn_and_ann(sklearn_knn, pynndescent_ann, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutaj predykcja ANN jest już wyraźnie szybsza - co prawda dane są niezbyt duże, więc nie ma to aż takiego znaczenia, ale widać potencjał skalowalności. Dodatkowo wynik jest taki sam.\n",
    "\n",
    "Różnice byłyby znacznie lepiej widoczne w algorytmach, które budują cały graf najbliższych sąsiadów. Poznamy je na laboratorium z redukcji wymiaru i selekcji cech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zbiór danych - klasyfikacja danych binarnych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz zajmiemy się klasyfikacją zbioru posiadającego same zmienne binarne, do których trzeba użyć odpowiednich metryk. Konkretnie, będzie to zbiór [HIV z benchmarku MoleculeNet](https://moleculenet.org/datasets-1), w którym na podstawie reprezentacji chemicznej molekuły trzeba przewidywać, czy jest ona inhibitorem wirusa HIV. [Inhibitory](https://en.wikipedia.org/wiki/Reaction_inhibitor) to substancje przeciwne do katalizatorów - spowalniają lub uniemożliwiają jakieś zjawisko, w naszym wypadku infekcję wirusa HIV. Przewidywanie własności molekuł to kluczowe zadanie w nowoczesnym projektowaniu leków i bardzo ważne zastosowanie ML w farmacji.\n",
    "\n",
    "Zbiór jest już podzielony na treningowy, walidacyjny i testowy w ramach projektu [Open Graph Benchmark](https://ogb.stanford.edu/docs/graphprop/). Dane te można traktować jak klasyfikację grafów molekularnych, ale w naszym wypadku zostały już one przetworzone do postaci tabelarycznej algorytmem [ECFP4 fingerprint](https://docs.chemaxon.com/display/docs/extended-connectivity-fingerprint-ecfp.md#:~:text=Extended%2DConnectivity%20Fingerprints%20(ECFPs),a%20wide%20variety%20of%20applications.). Konkretnie, z molekuł wyciągnięto informacje o 1024 podgrafach, gdzie wartość zmiennej mówi, czy dana struktura występuje w molekule, czy też nie.\n",
    "\n",
    "Jako że zbiór jest binarny, to nie ma potrzeby żadnego skalowania zmiennych.\n",
    "\n",
    "W przypadku tego zbioru oficjalną metryką [w benchmarku](https://ogb.stanford.edu/docs/leader_graphprop/) jest Area Under Receiver Operating Characteristic (AUROC / ROC AUC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 3 (1 punkt)**\n",
    "\n",
    "*Ładowanie danych*\n",
    "\n",
    "1. Wczytaj zbiory treningowy, walidacyjny i testowy. Są one w postaci plików Parquet.\n",
    "2. Wyodrębnij klasę `y` do osobnych zmiennych `y_train`, `y_valid`, `y_test`.\n",
    "3. Przekonwertuj macierze `X_train`, `X_valid` i `X_test` na typ bool ([przydatne pytanie na StackOverflow](https://stackoverflow.com/questions/20373039/how-do-i-convert-a-numpy-matrix-into-a-boolean-matrix)) - tak przechowywane dane zajmują mniej miejsca.\n",
    "4. Narysuj wykres częstości klas w zbiorze treningowym. Jak sądzisz, czemu akurat AUROC zostało tutaj wybrane jako metryka?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 4 (1.5 punktu)**\n",
    "\n",
    "*Trening klasyfikatora kNN*\n",
    "\n",
    "1. Wytrenuj klasyfikator kNN z domyślnymi hiperparametrami, używając metryki Jaccarda. Zmierz AUROC na zbiorze testowym. Pamiętaj, żeby przekazać odpowiednie wartości do metryki (patrz [przykład w dokumentacji](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)).\n",
    "2. Zmierz czas treningu oraz predykcji. Czy podczas treningu została zbudowana jakakolwiek struktura danych?\n",
    "3. Dokonaj tuningu liczby sąsiadów z zakresu [1, 5, 10]. Wykorzystaj tutaj istniejący zbiór walidacyjny z pomocą `PredefinedSplit`. Może się przydać [ta odpowiedź na StackOverflow](https://stackoverflow.com/a/70155766/9472066). Do tuningu wykorzystaj metrykę AUROC (argument `scoring`).\n",
    "4. Porównaj wyniki algorytmu po tuningu [z oficjalnym leaderboardem](https://ogb.stanford.edu/docs/leader_graphprop/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// skomentuj tutaj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 5 (1.5 punktu)**\n",
    "\n",
    "*Klasyfikacja z metryką Jaccarda*\n",
    "\n",
    "1. Stwórz pipeline do klasyfikacji ANN z użyciem PyNNDescent. Wykorzystaj metrykę Jaccarda i znalezioną wcześniej optymalną liczbę sąsiadów.\n",
    "2. Wytrenuj zwykłe kNN oraz ANN oraz dokonaj predykcji. Zmierz czas oraz dokładność obu metod. Czy twoim zdaniem warto dokonać w tym wypadku takiej aproksymacji?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wyszukiwanie z pomocą najbliższych sąsiadów"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naszym ostatnim zastosowaniem metod opartych o sąsiedztwo będzie wyszukiwanie przedmiotów. Konkretnie stworzymy wyszukiwarkę obrazów na podstawie wpisanego hasła.\n",
    "\n",
    "Jest to zadanie **multimodalne (multimodal)**, bo operujemy na dwóch różnych modalnościach: obrazie i tekście. Takie wyszukiwarki działają następująco:\n",
    "1. W fazie treningu przedmioty (obrazy) są wektoryzowane siecią neuronową i przechowywane w indeksie.\n",
    "2. Użytkownik wpisuje tekst, który jest wektoryzowany za pomocą tej samej sieci neuronowej, dlatego musi być ona multimodalna.\n",
    "3. Wyszukujemy najbliższych sąsiadów (obrazy-wektory) dla tekstu-wektora.\n",
    "\n",
    "Najbardziej znanym modelem multimodalnym jest [CLIP](https://openai.com/research/clip), stworzony przez OpenAI. Jego architektura i wagi są dostępne publicznie, w przeciwieństwie do nowych rozwiązań tej firmy. Jest to model zasadniczo niewymagający fine-tuningu, działa bardzo dobrze w podstawowej formie dla wielu zadań. Został też wykorzystany jako element modelu [DALL-E 2](https://openai.com/product/dall-e-2).\n",
    "\n",
    "Nie musisz szczegółowo wiedzieć, jak działa ten model, ale pewne podstawy są bardzo ciekawe i przydatne. Dla zainteresowanych [cały artykuł](https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language.pdf) - ale ostrzegam, że jest dość zaawansowany. Wysokopoziomowo architekturę dobrze opisuje [ten artykuł](https://towardsdatascience.com/clip-the-most-influential-ai-model-from-openai-and-how-to-use-it-f8ee408958b1). CLIP składa się z dwóch enkoderów: dla tekstu i dla obrazu. Są to zwykłe pre-trenowane sieci, a konkretnie:\n",
    "1. Dla obrazu - [Visual Transformer (ViT)](https://www.v7labs.com/blog/vision-transformer-guide). Jest to architektura, która używa transformerów i atencji do przetwarzania obrazów. Ideą jest, żeby pociąć obraz na sąsiadujące kawałki (patches), i traktować je jak słowa dla atencji.\n",
    "2. Dla tekstu - [Transformer](https://machinelearningmastery.com/the-transformer-model/), z pewnymi modyfikacjami.\n",
    "\n",
    "Każda z tych sieci wektoryzuje wejście, dając embedding.\n",
    "\n",
    "![CLIP](clip.png)\n",
    "\n",
    "Zbiorem danych była kolekcja 400 milionów par (obraz, tekst), gdzie tekst opisywał zawartość obrazu. Następnie wykonano **constrastive pre-training** - model dostaje batch $N$ par (obraz, tekst) i ma przewidzieć, które z $N \\times N$ możliwych kombinacji (obraz, tekst) faktycznie wystąpiły. W tym celu maksymalizuje podobieństwo cosinusowe par, które wystąpiły w batchu, a minimalizuje podobieństwo dla $N^2 - N$ możliwych kombinacji, których nie było w batchu. W tym celu jest używana entropia krzyżowa z pewnymi modyfikacjami.\n",
    "\n",
    "Widać więc, że model jest nienadzorowany, a zbiór danych był ogromny, więc fine-tuning nie jest nam zasadniczo potrzebny. Można go użyć do klasyfikacji, ale tym nie będziemy się zajmować. Dodatkowo odpowiednią metryką odległości dla najbliższych sąsiadów będzie podobieństwo cosinusowe.\n",
    "\n",
    "Biblioteka [Sentence-Transformers](https://www.sbert.net/index.html) powstała dla różnych modeli transformerowych do zadań nienadzorowanych, ale dodano do niej także bardzo wygodny interfejs dla modelu CLIP - [przykład użycia](https://www.sbert.net/examples/applications/image-search/README.html). \n",
    "\n",
    "Jako zbiór wykorzystamy [Amazon Berkeley Objects (ABO) Dataset](https://amazon-berkeley-objects.s3.amazonaws.com/index.html) - zbiór obrazów produktów Amazona, stworzony we współpracy z University of California, Berkeley. Wykorzystamy [zminiaturyzowany zbiór](https://amazon-berkeley-objects.s3.amazonaws.com/archives/abo-images-small.tar), w którym obrazy mają rozmiar 256x256 pikseli, bo na nasze potrzeby jest zupełnie wystarczający."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 6 (3 punkty)**\n",
    "\n",
    "*Wyszukiwarka z ANN*\n",
    "\n",
    "1. Ściągnij [zbiór danych](https://amazon-berkeley-objects.s3.amazonaws.com/archives/abo-images-small.tar). Rozpakuj go obok tego notebooka. W katalogu `images/metadata` znajdziesz plik `images.csv.gz` - rozpakuj go obok tego notebooka, zawiera on ścieżki do obrazów.\n",
    "2. Uzupełnij kod funkcji `vectorize_images`, która oblicza embeddingi obrazów za pomocą modelu CLIP. Przyda ci się [ten tutorial](https://www.sbert.net/examples/applications/image-search/README.html). Ustaw wartość MAX_IMAGES tak, żeby wystarczyło ci RAMu i żeby proces trwał rozsądną ilość czasu (ale co najmniej kilka-kilkanaście minut). `start_idx` oraz `end_idx` to indeksy wierszy, na których w danej chwili operujemy - po prostu przesuwamy się o `BATCH_SIZE` w pętli for.\n",
    "3. Uzupełnij kod klasy `ImageSearch`:\n",
    "  - w konstruktorze stwórz indeks za pomocą klasy [NNDescent](https://pynndescent.readthedocs.io/en/latest/api.html#pynndescent.pynndescent_.NNDescent), korzystając z metryki cosinusowej i `random_state=0`, może się też przydać `n_jobs=-1`\n",
    "  - w metodzie `query` zwektoryzuj zapytanie tekstowe, a następ wyszukaj indeksy najbliższych sąsiadów-obrazów w indeksie (zwróć uwagę na to, co zwraca metoda `.query()` dla `NNDescent`), a następnie zwróć ścieżki do ich obrazów; zwróć uwagę na to, że `.query()` wymaga 2-wymiarowego wejścia, więc w naszym wypadku `(1, 512)`\n",
    "  - w metodzie `show_images` załaduj i wyświetl obrazy; może się przydać [ten przykład](https://matplotlib.org/stable/gallery/axes_grid1/simple_axesgrid.html)\n",
    "4. Przetestuj wyszukiwarkę kilkoma hasłami (metoda `.search()`). Prawdopodobnie najlepiej zadziałają hasła odpowiadające typowym produktom sprzedawanym w Amazonie.\n",
    "5. Jakie widzisz zalety i wady takiego podejścia do wyszukiwania?\n",
    "\n",
    "**Uwaga:** jeżeli masz mało RAMu lub pracujesz na Google Colab, to warto zrestartować Jupyter Notebooka, zamykając kernel. Zwolni ci to pamięć. Możesz też usunąć macierz z embeddingami (`del embeddings`) kiedy stworzysz indeks w konstruktorze `ImageSearch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare pd.Series with paths to images\n",
    "image_paths = pd.read_csv(\"images.csv\")\n",
    "\n",
    "# \"height\" and \"width\" are original image size, let's select\n",
    "# only large ones - they are probably more interesting\n",
    "mask = (image_paths[\"height\"] >= 1000) & (image_paths[\"width\"] >= 1000)\n",
    "image_paths = image_paths.loc[mask, :]\n",
    "\n",
    "# remove columns, leaving only pd.Series with paths\n",
    "image_paths = image_paths[\"path\"]\n",
    "image_paths = \"images/small/\" + image_paths.astype(str)\n",
    "\n",
    "image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "import joblib\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "MAX_IMAGES = 10000\n",
    "BATCH_SIZE = joblib.cpu_count(only_physical_cores=True)\n",
    "\n",
    "\n",
    "def vectorize_images(\n",
    "    image_paths: pd.Series\n",
    ") -> np.ndarray:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = SentenceTransformer(\"clip-ViT-B-32\", device=device)\n",
    "    \n",
    "    # batch iterator, based on Python itertools example\n",
    "    def batched(iterable, n: int):\n",
    "        it = iter(iterable)\n",
    "        while (batch := tuple(islice(it, n))):\n",
    "            yield batch\n",
    "    \n",
    "    # CLIP embeddings have 512 dimensions\n",
    "    embeddings = np.empty((MAX_IMAGES, 512))\n",
    "    \n",
    "    # iterate with tqdm, it will give us a nice progress bar\n",
    "    with tqdm(total=MAX_IMAGES) as pbar:\n",
    "        start_idx = 0\n",
    "        for batch in batched(image_paths.iloc[:MAX_IMAGES], BATCH_SIZE):\n",
    "            # update end_idx; remember to stop at MAX_IMAGES!\n",
    "            \n",
    "\n",
    "            # load images with Image.open()\n",
    "            \n",
    "            \n",
    "            # calculate embeddings\n",
    "            \n",
    "\n",
    "            # save embeddings in the embeddings array\n",
    "            \n",
    "            \n",
    "            # update start_idx\n",
    "            \n",
    "\n",
    "            pbar.update(BATCH_SIZE)\n",
    "    \n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = vectorize_images(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynndescent import NNDescent\n",
    "\n",
    "\n",
    "class ImageSearch:\n",
    "    def __init__(self, image_paths: pd.Series, embeddings: np.ndarray):\n",
    "        # change to Numpy array to avoid .iloc[] and just index with []\n",
    "        self.image_paths = image_paths.values\n",
    "        \n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model = SentenceTransformer(\"clip-ViT-B-32\", device=device)\n",
    "        \n",
    "        # create PyNNDescent index\n",
    "        self.index = ...\n",
    "\n",
    "    def search(self, text: str, n_neighbors: int = 9) -> None:\n",
    "        image_paths = self.query(text, n_neighbors)\n",
    "        self.show(image_paths)\n",
    "        \n",
    "    def query(self, text: str, n_neighbors: int = 9) -> list[str]:\n",
    "        ...\n",
    "\n",
    "    def show(self, image_paths: list[str]) -> None:\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_search = ImageSearch(image_paths, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_search.search(\"blue pillow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// skomentuj tutaj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PUM",
   "language": "python",
   "name": "pum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
